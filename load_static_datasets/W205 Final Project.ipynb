{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W205 Final Project.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "dBIKWcB_BpaN",
        "colab_type": "text"
      },
      "source": [
        "# W205 Final Project\n",
        "\n",
        "#### James Black, Ramsey Magana, Aniruddh Nautiyal, Rich Ung\n",
        "\n",
        "GitHub repository for the project can be found here: https://github.com/RichUng/w205-final-project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "fCdB0Fyfrbwt",
        "colab_type": "text"
      },
      "source": [
        "## Install packages necessary to run the below script"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "EkiDljPpqHnU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 5
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cb32afba-e6a8-4187-d9e0-2c68aee03406",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513492772484,
          "user_tz": 420,
          "elapsed": 7311,
          "user": {
            "displayName": "Aniruddh Nautiyal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106625565908239559865"
          }
        }
      },
      "source": [
        "!pip install --upgrade gtfs-realtime-bindings\n",
        "!pip install boto3\n",
        "!pip install psycopg2"
      ],
      "cell_type": "code",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gtfs-realtime-bindings in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (from gtfs-realtime-bindings)\n",
            "Requirement already up-to-date: protobuf in /usr/local/lib/python3.6/dist-packages (from gtfs-realtime-bindings)\n",
            "Requirement already up-to-date: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->gtfs-realtime-bindings)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3)\n",
            "Requirement already satisfied: botocore<1.9.0,>=1.8.15 in /usr/local/lib/python3.6/dist-packages (from boto3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.9.0,>=1.8.15->boto3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.9.0,>=1.8.15->boto3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.9.0,>=1.8.15->boto3)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.6/dist-packages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pNOY7_rbB_71",
        "colab_type": "text"
      },
      "source": [
        "## Load static datasets into Amazon S3"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "8UWiFZi1B_JS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "## Connect to s3\n",
        "\n",
        "import boto3\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "ACCESS_KEY = 'AKIAJP4ASR6L7P6X2YIQ'\n",
        "SECRET_KEY = '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'\n",
        "\n",
        "\n",
        "s3 = boto3.resource(\n",
        "    's3',\n",
        "    aws_access_key_id=ACCESS_KEY,\n",
        "    aws_secret_access_key=SECRET_KEY\n",
        ")"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DzWlqb-pueL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "## Operator List\n",
        "import boto3\n",
        "import os, shutil\n",
        "import pandas as pd\n",
        "import json\n",
        "import urllib.request\n",
        "\n",
        "CWD = os.getcwd()\n",
        "\n",
        "BUCKET_NAME = 'w205-redshift-intermediate'\n",
        "\n",
        "DIR_1 = CWD+'/my_directory/'\n",
        "\n",
        "## gtfs_operator_list.csv\n",
        "\n",
        "response = urllib.request.urlopen('http://api.511.org/transit/gtfsoperators?api_key=baa045f5-dff4-44f4-ad59-8d50f70b12ad&format=json')\n",
        "\n",
        "body = response.read().decode('utf-8-sig')\n",
        "json_data = json.loads(body)\n",
        "df = pd.io.json.json_normalize(json_data)\n",
        "\n",
        "try:\n",
        "    os.mkdir(DIR_1)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "\n",
        "df.to_csv(DIR_1+'gtfs_operator_list.csv', index=False)\n",
        "s3.Object(BUCKET_NAME, 'static_operators/'+'gtfs_operator_list.csv').put(Body=open(DIR_1+'gtfs_operator_list.csv', 'rb'))\n",
        "\n",
        "shutil.rmtree(DIR_1)"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGamQcTppxDV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 6
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7e6956e3-657c-44ee-b356-1cd015b62510",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513492779127,
          "user_tz": 420,
          "elapsed": 5034,
          "user": {
            "displayName": "Aniruddh Nautiyal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106625565908239559865"
          }
        }
      },
      "source": [
        "## DATAFEEDS\n",
        "import boto3\n",
        "import requests, zipfile, io, os\n",
        "import os, shutil\n",
        "import pandas as pd\n",
        "import json\n",
        "import urllib.request\n",
        "\n",
        "APIKEY_511 = 'c446f9f0-5979-4667-a37b-d31b41480fa9'\n",
        "URL_PREFIX =  'http://api.511.org/transit/datafeeds?api_key='\n",
        "\n",
        "AGENCY_LIST = ['3D','AC','CC','SF','SR','VN']\n",
        "\n",
        "BUCKET_NAME = 'w205-redshift-intermediate'\n",
        "\n",
        "CWD = os.getcwd()\n",
        "\n",
        "DIR_1 = CWD+'/my_directory/'\n",
        "\n",
        "DIR_2 = CWD+'/tripsdir/'\n",
        "\n",
        "## datafeed files\n",
        "\n",
        "for agency in AGENCY_LIST:\n",
        "    \n",
        "    try:\n",
        "        r = requests.get(URL_PREFIX+str(APIKEY_511)+'&operator_id='+str(agency))\n",
        "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "        z.extractall(DIR_1)\n",
        "\n",
        "        if not os.path.exists(DIR_2):\n",
        "            os.makedirs(DIR_2)\n",
        "        \n",
        "        \n",
        "        FILENAME = 'trips'+str(agency)+'.txt'\n",
        "\n",
        "        os.rename(DIR_1+'trips.txt', DIR_2+FILENAME)\n",
        "\n",
        "        #delete the directory and contents\n",
        "        shutil.rmtree(DIR_1)\n",
        "        \n",
        "        # Read file as pandas frame and append column\n",
        "        df = pd.read_csv(DIR_2+FILENAME)\n",
        "        df['agency'] = agency\n",
        "        data = df.to_csv(index=False)\n",
        "\n",
        "        # Write file to S3\n",
        "        s3.Bucket(BUCKET_NAME).put_object(Key='static_datafeed/'+FILENAME, Body=data)\n",
        "        print('Agency successfully uploaded: '+agency)\n",
        "        \n",
        "    except:\n",
        "        print('Agency failed upload: '+agency)\n",
        "        pass   \n",
        "    \n",
        "shutil.rmtree(DIR_2)\n",
        "        "
      ],
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agency successfully uploaded: 3D\n",
            "Agency successfully uploaded: AC\n",
            "Agency successfully uploaded: CC\n",
            "Agency successfully uploaded: SF\n",
            "Agency successfully uploaded: SR\n",
            "Agency successfully uploaded: VN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U4vPQgyzHKHb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "##### CRIME DATA\n",
        "import boto3\n",
        "\n",
        "import urllib.request\n",
        "import os, shutil, zipfile, io\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "\n",
        "DIR_1 = CWD+'/my_directory/'\n",
        "\n",
        "\n",
        "##### CRIME DATA\n",
        "\n",
        "response = urllib.request.urlopen('https://data.sfgov.org/api/views/9v2m-8wqu/rows.json?accessType=DOWNLOAD')\n",
        "body = response.read().decode('utf-8-sig')\n",
        "json_data = json.loads(body)\n",
        "\n",
        "try:\n",
        "    os.mkdir(DIR_1)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "crime_headers = [i['fieldName'] for i in json_data['meta']['view']['columns']]\n",
        "\n",
        "with open(DIR_1+'sf_crime.csv', 'w', newline='') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
        "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    \n",
        "    spamwriter.writerow(crime_headers)\n",
        "    for line in json_data['data']:\n",
        "        spamwriter.writerow(','.join(str(line)))\n",
        "\n",
        "s3.Object(BUCKET_NAME, 'static_crime/'+'sf_crime.csv').put(Body=open(DIR_1+'sf_crime.csv', 'rb'))        \n",
        "        \n",
        "        \n",
        "\n",
        "shutil.rmtree(DIR_1)\n"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EiWU6hREHKJ4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "##### INCOME DATA\n",
        "import boto3\n",
        "\n",
        "import urllib.request\n",
        "import os, shutil, zipfile, io\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "\n",
        "response = urllib.request.urlopen('https://www.irs.gov/pub/irs-soi/15zpallagi.csv')\n",
        "string = response.read().decode('utf-8-sig')\n",
        "\n",
        "body =  string.split('\\n')\n",
        "\n",
        "try:\n",
        "    os.mkdir(DIR_1)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "with open(DIR_1+'irs_income.csv', 'w', newline='') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
        "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    \n",
        "    for line in body:\n",
        "        spamwriter.writerow(line)\n",
        "\n",
        "s3.Object(BUCKET_NAME, 'static_income/'+'irs_income.csv').put(Body=open(DIR_1+'irs_income.csv', 'rb'))\n",
        "        \n",
        "shutil.rmtree(DIR_1)\n",
        "    \n"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-j3Cs4pVCF-U",
        "colab_type": "text"
      },
      "source": [
        "## Load S3 static dataset objects into Amazon Redshift"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "lDUDzjtIOPb-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# To push static data from S3 bucket to Amazon redshift database\n",
        "\n",
        "import psycopg2\n",
        "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
        "\n",
        "# Connection fields\n",
        "thisdb            = \"dev\"\n",
        "thisuser          = \"w205\"\n",
        "thispassword      = \"W205final\"\n",
        "thishost          = \"w205-final-project.cspk3mfgs5hv.us-east-1.redshift.amazonaws.com\"\n",
        "thisport          = \"5439\"\n",
        "\n",
        "# S3 static buckets URLs here\n",
        "\n",
        "s3_load_buckets   = ['s3://w205-redshift-intermediate/static_operators',\n",
        "                     's3://w205-redshift-intermediate/static_datafeed',\n",
        "                     's3://w205-redshift-intermediate/static_crime',\n",
        "                     's3://w205-redshift-intermediate/static_income']\n",
        "\n",
        "# Connection to the database\n",
        "conn = psycopg2.connect(database=thisdb, user=thisuser, password=thispassword, host=thishost, port=thisport)\n",
        "\n",
        "cur = conn.cursor()\n",
        "\n",
        "# load operator_list tables\n",
        "\n",
        "cur.execute('''COPY operator_list\n",
        "               FROM %s\n",
        "               CREDENTIALS 'aws_access_key_id=AKIAIJPY52GPN4J6LKWQ;aws_secret_access_key=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'\n",
        "               DELIMITER ','\n",
        "               REMOVEQUOTES\n",
        "               IGNOREHEADER 1\n",
        "               REGION 'us-east-1'\n",
        "               ;''', (s3_load_buckets[0],) )\n",
        "conn.commit()\n",
        "\n",
        "# load data_feed table\n",
        "\n",
        "cur.execute('''COPY data_feed\n",
        "               FROM %s\n",
        "               CREDENTIALS 'aws_access_key_id=AKIAIJPY52GPN4J6LKWQ;aws_secret_access_key=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'\n",
        "               DELIMITER ','\n",
        "               REMOVEQUOTES\n",
        "               IGNOREHEADER 1\n",
        "               REGION 'us-east-1'\n",
        "               ;''', (s3_load_buckets[1],) )\n",
        "conn.commit()\n",
        "\n",
        "# load crime_data table\n",
        "\n",
        "cur.execute('''COPY crime_data\n",
        "               FROM %s\n",
        "               CREDENTIALS 'aws_access_key_id=AKIAIJPY52GPN4J6LKWQ;aws_secret_access_key=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'\n",
        "               DELIMITER ','\n",
        "               REMOVEQUOTES\n",
        "               IGNOREHEADER 1\n",
        "               ESCAPE\n",
        "               REGION 'us-east-1'\n",
        "               ;''', (s3_load_buckets[2],) )\n",
        "conn.commit()\n",
        "\n",
        "# load income_data table\n",
        "\n",
        "cur.execute('''COPY income_data\n",
        "               FROM %s\n",
        "               CREDENTIALS 'aws_access_key_id=AKIAIJPY52GPN4J6LKWQ;aws_secret_access_key=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'\n",
        "               DELIMITER ','\n",
        "               REMOVEQUOTES\n",
        "               IGNOREHEADER 1\n",
        "               IGNOREBLANKLINES\n",
        "               REGION 'us-east-1'\n",
        "               ;''', (s3_load_buckets[3],) )\n",
        "conn.commit()\n",
        "\n",
        "conn.close()"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YgARWD-SCh5D",
        "colab_type": "text"
      },
      "source": [
        "## Ad-hoc script to push streaming data into Amazon Kinesis\n",
        "\n",
        "This script runs once every minute through an Amazon Lambda function"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "KnXaQp9fHkCJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "43bfb590-60f4-47b2-b3e7-5006c754e8a1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513492870988,
          "user_tz": 420,
          "elapsed": 1025,
          "user": {
            "displayName": "Aniruddh Nautiyal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106625565908239559865"
          }
        }
      },
      "source": [
        "import boto3\n",
        "import time\n",
        "import urllib.request\n",
        "from google.transit import gtfs_realtime_pb2\n",
        "\n",
        "# All agencies\n",
        "# agencies = ['3D','AC','AM','AT','AY','BA','BG','CC','CE','CM','CT','DE','EM','FS','GF','GG','HF','MA','MS','PE','RV','SA','SB','SC','SF','SM','SO','SR','ST','UC','VC','VN','WC','WH']\n",
        "\n",
        "# All succcessful API call agencies\n",
        "# agencies = ['3D','AC','BA','CC','CT','DE','GG','MA','SC','SF','SM','SR','VN','WC']\n",
        "\n",
        "# All succcessful API call agencies that return vehicle positions\n",
        "agencies = ['3D','AC','CC','SF','SR','VN']\n",
        "\n",
        "kinesis_client = boto3.client('kinesis', region_name='us-east-1', \n",
        "    aws_access_key_id='AKIAJP4ASR6L7P6X2YIQ',\n",
        "    aws_secret_access_key='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')\n",
        "\n",
        "# Pick a specific agency depending on the minute\n",
        "minute = int(time.strftime(\"%M\"))\n",
        "agency = agencies[minute % len(agencies)]\n",
        "print(\"Loading Agency:\",agency)\n",
        "\n",
        "# Load latest vehicle positions for agency and send data to Kinesis\n",
        "try:\n",
        "  feed = gtfs_realtime_pb2.FeedMessage()\n",
        "  response = urllib.request.urlopen('http://api.511.org/Transit/VehiclePositions?api_key=c446f9f0-5979-4667-a37b-d31b41480fa9&agency='+agency)\n",
        "  feed.ParseFromString(response.read())\n",
        "\n",
        "  print(\"Sending\", len(feed.entity), agency, \"rows to Kinesis\")\n",
        "  \n",
        "  for x in range(0, len(feed.entity)):\n",
        "    put_response = kinesis_client.put_record(\n",
        "        StreamName = 'W205',\n",
        "        Data = \"{}, {}, {}, {}, {}, {} \\n\".format(\n",
        "                feed.entity[x].vehicle.vehicle.id, \n",
        "                feed.entity[x].vehicle.timestamp,\n",
        "                feed.entity[x].vehicle.position.latitude,\n",
        "                feed.entity[x].vehicle.position.longitude,\n",
        "                feed.entity[x].vehicle.trip.trip_id,\n",
        "                agency),\n",
        "        PartitionKey = \"abc123\")\n",
        "  print(agency,\"Successful\")\n",
        "except:\n",
        "  print(agency,\"Failed\")"
      ],
      "cell_type": "code",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Agency: VN\n",
            "Sending 0 VN rows to Kinesis\n",
            "VN Successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FTNO3Knill1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        ""
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    }
  ]
}